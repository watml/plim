{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from numpy import linalg as LA\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "with open(\"17_mnist.pkl\", \"br\") as fh:\n",
    "    data = pickle.load(fh)\n",
    "\n",
    "train_imgs = data[0]\n",
    "test_imgs = data[1]\n",
    "train_labels = data[2]\n",
    "test_labels = data[3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for i in range(len(train_labels)):\n",
    "    if train_labels[i]==7:\n",
    "        train_labels[i]=np.array([0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.FloatTensor(train_imgs)\n",
    "train_y = torch.FloatTensor(train_labels)\n",
    "#train_y = train_y.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        assert X.size()[0] == y.size()[0]\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.size()[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return [self.X[idx], self.y[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda'\n",
    "\n",
    "class LR(nn.Module):\n",
    "    def __init__(self, input_size=784, num_class=1):\n",
    "        super(LR, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, num_class)\n",
    "        self.act=nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        return (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(LinearDataset(train_x, train_y), batch_size=len(train_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LR().to(device).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 784])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = model.state_dict()\n",
    "print(state_dict['fc1.weight'].size())\n",
    "state_dict['fc1.weight'] = torch.ones(1,784)\n",
    "state_dict['fc1.bias'] = torch.Tensor([-20])\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> start gradient canceling attack with given target parameters\n",
      "==> model will be saved in poisoned_models\n",
      "tensor([[0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],\n",
      "        [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],\n",
      "        [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],\n",
      "        ...,\n",
      "        [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],\n",
      "        [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],\n",
      "        [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "0.06314240582474075\n",
      "the necessary size of epsilon_d:(0.2267520496457524+0j)\n"
     ]
    }
   ],
   "source": [
    "def autograd(outputs, inputs, create_graph=False):\n",
    "    \"\"\"Compute gradient of outputs w.r.t. inputs, assuming outputs is a scalar.\"\"\"\n",
    "    #inputs = tuple(inputs)\n",
    "    grads = torch.autograd.grad(outputs, inputs, create_graph=create_graph, allow_unused=True)\n",
    "    return [xx if xx is not None else yy.new_zeros(yy.size()) for xx, yy in zip(grads, inputs)]\n",
    "\n",
    "from scipy.special import lambertw\n",
    "import math\n",
    "lambert_w = lambertw(1/math.e)\n",
    "\n",
    "\n",
    "\n",
    "def tau(epoch,lr):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device).double(), target.to(device).double()\n",
    "        # initialize f function\n",
    "        criterion = nn.BCELoss()\n",
    "        \n",
    "        # calculate gradient of w on clean sample\n",
    "        output_c = model(data.view(data.size(0), -1))\n",
    "        #output_c = model(data)\n",
    "        loss_c = criterion(output_c,target)\n",
    "        # wrt to w here\n",
    "        grad_c= autograd(loss_c,tuple(model.parameters()),create_graph=True)\n",
    "        g1 = grad_c[0]\n",
    "        torch.save(g1.detach(), 'gmu_lr.pt')\n",
    "        \n",
    "        g1 = torch.flatten(g1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        w_p = model.fc1.weight\n",
    "        \n",
    "        w_p = torch.flatten(w_p)\n",
    "        g_mu_dot_w = np.dot(g1.cpu().detach().numpy().squeeze(),w_p.cpu().detach().numpy().squeeze())\n",
    "        print(g_mu_dot_w)\n",
    "        \n",
    "        print('the necessary size of epsilon_d:{}'.format(g_mu_dot_w/lambert_w))\n",
    "        break\n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "print(\"==> start gradient canceling attack with given target parameters\")\n",
    "print(\"==> model will be saved in poisoned_models\")\n",
    "epochs=1\n",
    "lr=1\n",
    "for epoch in range(epochs):\n",
    "    tau(epoch,lr)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 784])\n",
      "==> start gradient canceling attack with given target parameters\n",
      "==> model will be saved in poisoned_models\n",
      "epoch:0,loss:5.790360160597739e-33,lr:0.1\n",
      "epoch:1,loss:5.7903434080583965e-33,lr:0.1\n",
      "epoch:2,loss:5.79032665556752e-33,lr:0.1\n",
      "epoch:3,loss:5.790309903125115e-33,lr:0.1\n",
      "epoch:4,loss:5.790293150731175e-33,lr:0.1\n",
      "epoch:5,loss:5.7902763983857034e-33,lr:0.1\n",
      "epoch:6,loss:5.7902596460887e-33,lr:0.1\n",
      "epoch:7,loss:5.7902428938401625e-33,lr:0.1\n",
      "epoch:8,loss:5.790226141640095e-33,lr:0.1\n",
      "epoch:9,loss:5.790209389488492e-33,lr:0.1\n",
      "epoch:10,loss:5.790192637385356e-33,lr:0.1\n",
      "epoch:11,loss:5.790175885330689e-33,lr:0.1\n",
      "epoch:12,loss:5.790159133324487e-33,lr:0.1\n",
      "epoch:13,loss:5.790142381366751e-33,lr:0.1\n",
      "epoch:14,loss:5.7901256294574835e-33,lr:0.1\n",
      "epoch:15,loss:5.79010887759668e-33,lr:0.1\n",
      "epoch:16,loss:5.7900921257843426e-33,lr:0.1\n",
      "epoch:17,loss:5.790075374020472e-33,lr:0.1\n",
      "epoch:18,loss:5.790058622305069e-33,lr:0.1\n",
      "epoch:19,loss:5.790041870638129e-33,lr:0.1\n",
      "epoch:20,loss:5.790025119019657e-33,lr:0.1\n",
      "epoch:21,loss:5.7900083674496475e-33,lr:0.1\n",
      "epoch:22,loss:5.789991615928106e-33,lr:0.1\n",
      "epoch:23,loss:5.7899748644550266e-33,lr:0.1\n",
      "epoch:24,loss:5.789958113030414e-33,lr:0.1\n",
      "epoch:25,loss:5.7899413616542665e-33,lr:0.1\n",
      "epoch:26,loss:5.7899246103265836e-33,lr:0.1\n",
      "epoch:27,loss:5.7899078590473646e-33,lr:0.1\n",
      "epoch:28,loss:5.789891107816611e-33,lr:0.1\n",
      "epoch:29,loss:5.789874356634321e-33,lr:0.1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-211f3aab88cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mattack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-74-211f3aab88cf>\u001b[0m in \u001b[0;36mattack\u001b[0;34m(epoch, lr)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mloss_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mattack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-fc8cd564518c>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adadelta(model.parameters(), lr=0.1)\n",
    "# define epsilon for one point for now\n",
    "epsilon = 0.01\n",
    "\n",
    "\n",
    "\n",
    "# load gmu to initialize the poisoned samples\n",
    "gmu = torch.load('gmu_lr.pt')\n",
    "print(gmu.size())\n",
    "\n",
    "loss_all = []\n",
    "def attack(epoch,lr):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device).double(), target.to(device).double()\n",
    "        data.requires_grad=True\n",
    "        if epoch==0:\n",
    "            # initialize poisoned data with 1/epsilon g(mu)\n",
    "            #data_p = Variable(data[:epsilon])\n",
    "            data_p = Variable((gmu))\n",
    "            target_p = Variable(torch.ones([1,1])).to(device).double()\n",
    "            torch.save(target_p,'target_p_{}.pt'.format(epsilon))\n",
    "        else:\n",
    "            data_p = torch.load('data_p_{}.pt'.format(epsilon))\n",
    "            target_p = torch.load('target_p_{}.pt'.format(epsilon))\n",
    "        data_p.requires_grad=True\n",
    "        # initialize f function with average\n",
    "        criterion = nn.BCELoss()\n",
    "        \n",
    "        # calculate gradient of w on clean sample\n",
    "        output_c = model(data.view(data.size(0), -1))\n",
    "        loss_c = criterion(output_c,target)\n",
    "        # wrt to w here\n",
    "        grad_c= autograd(loss_c,tuple(model.parameters()),create_graph=True)\n",
    "        g1 = grad_c[0]\n",
    "        \n",
    "        \n",
    "        # calculate gradient of w on poisoned sample\n",
    "        output_p = model(data_p.view(data_p.size(0), -1))\n",
    "\n",
    "        loss_p = criterion(output_p,target_p)\n",
    "        grad_p= autograd(loss_p,tuple(model.parameters()),create_graph=True)\n",
    "        g2 = grad_p[0]\n",
    "        # calculate the true loss: |g_c + g_p|_{inf}\n",
    "        \n",
    "        grad_sum = g1+(epsilon*g2)\n",
    "\n",
    "        \n",
    "        loss = torch.norm(grad_sum,2).square()\n",
    "        loss_all.append(loss.detach().cpu().numpy())\n",
    "            \n",
    "        update = autograd(loss,data_p,create_graph=True)\n",
    "        #print(update)\n",
    "        \n",
    "        data_t = data_p - lr * update[0]\n",
    "\n",
    "        torch.save(data_t, 'data_p_{}.pt'.format(epsilon))\n",
    "        \n",
    "        \n",
    "        print(\"epoch:{},loss:{},lr:{}\".format(epoch, loss,lr))\n",
    "\n",
    "        \n",
    "        \n",
    "print(\"==> start gradient canceling attack with given target parameters\")\n",
    "print(\"==> model will be saved in poisoned_models\")\n",
    "epochs=2000\n",
    "lr= 0.1\n",
    "for epoch in range(epochs):\n",
    "    attack(epoch,lr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
